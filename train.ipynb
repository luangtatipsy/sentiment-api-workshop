{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import html\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Load Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'dataset/wisesight-sentiment-master/'\n",
    "negative_path = os.path.join(directory, 'neg.txt')\n",
    "neutral_path = os.path.join(directory, 'neu.txt')\n",
    "positive_path = os.path.join(directory, 'pos.txt')\n",
    "question_path = os.path.join(directory, 'q.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(negative_path) as file:\n",
    "  negative_texts = file.read().splitlines(False)\n",
    "  \n",
    "with open(neutral_path) as file:\n",
    "  neutral_texts = file.read().splitlines(False)\n",
    "  \n",
    "with open(positive_path) as file:\n",
    "  positive_texts = file.read().splitlines(False)\n",
    "  \n",
    "with open(question_path) as file:\n",
    "  question_texts = file.read().splitlines(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['text', 'label']\n",
    "sentiment_df = pd.DataFrame(columns=cols)\n",
    " \n",
    "all_texts = (positive_texts, neutral_texts, negative_texts)\n",
    "all_labels = ('positive', 'neutral', 'negative')\n",
    "\n",
    "for texts, label in zip(all_texts, all_labels):\n",
    "  tmp = pd.DataFrame({\"text\": texts, 'label': label})\n",
    "  sentiment_df = sentiment_df.append(tmp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Data Exploration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentences: 4778 sentences\n",
      "Neutral Sentences: 14573 sentences\n",
      "Negative Sentences: 6824 sentences\n"
     ]
    }
   ],
   "source": [
    "values = sentiment_df['label'].value_counts()\n",
    "\n",
    "print(f\"Positive Sentences: {values['positive']} sentences\")\n",
    "print(f\"Neutral Sentences: {values['neutral']} sentences\")\n",
    "print(f\"Negative Sentences: {values['negative']} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Data Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import normalize_thai_number, normalize_number, remove_markup_tag, normalize_link, normalize_mention \n",
    "from preprocess import normalize_email, normalize_laugh, unescape_html, normalize_emoji, extract_hashtag\n",
    "from preprocess import normalize_hashtag, replace_with_actual_hashtag, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['preprocessed'] = sentiment_df['text'].apply(lambda text: text.lower())\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_thai_number)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(unescape_html)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(remove_markup_tag)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_link)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_mention)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_email)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_laugh)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(lambda text: normalize_number(text, place_holder=''))\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(normalize_emoji)\n",
    "sentiment_df['hashtags'] = sentiment_df['preprocessed'].apply(extract_hashtag)\n",
    "sentiment_df['preprocessed'] = sentiment_df['preprocessed'].apply(lambda text: normalize_hashtag(text, place_holder=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.corpus import thai_stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stopwords = thai_stopwords()\n",
    "punctuation += '‚Äú‚Äù Ô∏è'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['tokens'] = sentiment_df['preprocessed'].apply(lambda text: tokenize(text, punctuation=punctuation))\n",
    "sentiment_df['tokens'] = sentiment_df.apply(lambda row: replace_with_actual_hashtag(row['tokens'], row['hashtags']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏î‡∏µ‡∏Å‡πà‡∏≤‡∏™‡∏≤</td>\n",
       "      <td>neutral</td>\n",
       "      <td>‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏î‡∏µ‡∏Å‡πà‡∏≤‡∏™‡∏≤</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ, ‡∏î‡∏µ‡∏Å‡πà‡∏≤, ‡∏™‡∏≤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9199</th>\n",
       "      <td>‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏°‡∏©‡∏≤‡πÑ‡∏õ‡∏Å‡∏±‡∏ô</td>\n",
       "      <td>neutral</td>\n",
       "      <td>‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏°‡∏©‡∏≤‡πÑ‡∏õ‡∏Å‡∏±‡∏ô</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡∏™‡∏ô‡πÉ‡∏à, ‡πÑ‡∏´‡∏°, ‡∏ä‡πà‡∏ß‡∏á, ‡πÄ‡∏°‡∏©‡∏≤, ‡πÑ‡∏õ, ‡∏Å‡∏±‡∏ô]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>‡πÄ‡∏à‡πâ‡πÜ ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏ô‡∏¥‡πÄ‡∏¢‡πà #‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏™‡∏ß‡∏¢‡∏î‡∏µ üòÇüòÇ</td>\n",
       "      <td>positive</td>\n",
       "      <td>‡πÄ‡∏à‡πâ‡πÜ ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏ô‡∏¥‡πÄ‡∏¢‡πà  üòÇ  üòÇ</td>\n",
       "      <td>[#‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏™‡∏ß‡∏¢‡∏î‡∏µ]</td>\n",
       "      <td>[‡πÄ‡∏à‡πâ, ‡πÜ, ‡πÄ‡∏´‡πá‡∏ô, ‡∏ß‡πà‡∏≤, ‡πÉ‡∏ä‡πâ, ‡∏Å‡∏≤, ‡∏ô‡∏¥, ‡πÄ‡∏¢‡πà, üòÇ, üòÇ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25525</th>\n",
       "      <td>‡∏ñ‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á CR-V ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ú‡∏°‡∏ä‡∏≠‡∏ö‡πÇ‡∏â‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏Ñ‡∏°‡∏£‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡∏£‡∏ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏•‡πâ‡∏≤‡∏ô‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏ñ‡∏∂‡∏á‡∏•‡πâ‡∏≤‡∏ô‡∏õ‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏ó ‡∏ú‡∏°‡∏Å‡πá‡∏Ñ‡∏á‡πÄ‡∏•‡πà‡∏ô SUV ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞</td>\n",
       "      <td>negative</td>\n",
       "      <td>‡∏ñ‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á cr-v ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ú‡∏°‡∏ä‡∏≠‡∏ö‡πÇ‡∏â‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏Ñ‡∏°‡∏£‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡∏£‡∏ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏•‡πâ‡∏≤‡∏ô‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏ñ‡∏∂‡∏á‡∏•‡πâ‡∏≤‡∏ô‡∏õ‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏ó ‡∏ú‡∏°‡∏Å‡πá‡∏Ñ‡∏á‡πÄ‡∏•‡πà‡∏ô suv ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡∏ñ‡πâ‡∏≤, ‡πÅ‡∏ö‡∏ö, ‡∏ô‡∏±‡πâ‡∏ô, ‡∏Ñ‡∏á, ‡∏ï‡πâ‡∏≠‡∏á, ‡∏î‡∏π, ‡∏¢‡∏≠‡∏î, ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á, ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á, ‡∏ß‡πà‡∏≤, ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤, ‡∏°‡∏±‡πâ‡∏¢, ‡πÅ‡∏ï‡πà, ‡∏ú‡∏°, ‡∏ä‡∏≠‡∏ö, ‡πÇ‡∏â‡∏°, ‡∏ô‡∏µ‡πâ, ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤, ‡πÅ‡∏Ñ‡∏°, ‡∏£‡∏µ‡πà, ‡πÉ‡∏´‡∏°‡πà, ‡∏ô‡∏∞, ‡πÅ‡∏ï‡πà, ‡∏ñ‡πâ‡∏≤, ‡πÄ‡∏õ‡πá‡∏ô, ‡πÉ‡∏ô, ‡πÄ‡∏°‡∏∑‡∏≠‡∏á, ‡πÑ‡∏ó‡∏¢, ‡∏£‡∏ñ, ‡∏£‡∏≤‡∏Ñ‡∏≤, ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì, ‡∏•‡πâ‡∏≤‡∏ô, ‡∏Ñ‡∏£‡∏∂‡πà‡∏á, ‡∏ñ‡∏∂‡∏á, ‡∏•‡πâ‡∏≤‡∏ô, ‡∏õ‡∏•‡∏≤‡∏¢, ‡πÅ‡∏ö‡∏ö, ‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå, ‡∏ó, ‡∏ú‡∏°, ‡∏Å‡πá, ‡∏Ñ‡∏á, ‡πÄ‡∏•‡πà‡∏ô, suv, ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏≤‡∏≤ ^^</td>\n",
       "      <td>neutral</td>\n",
       "      <td>‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏≤‡∏≤ ^^</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡πÑ‡∏°‡πà‡∏°‡∏µ, ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢, ‡∏Ñ‡πà‡∏≤, ‡∏≤‡∏≤]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                          text  \\\n",
       "7264   ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏î‡∏µ‡∏Å‡πà‡∏≤‡∏™‡∏≤                                                                                                                                                                             \n",
       "9199   ‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏°‡∏©‡∏≤‡πÑ‡∏õ‡∏Å‡∏±‡∏ô                                                                                                                                                                      \n",
       "3187   ‡πÄ‡∏à‡πâ‡πÜ ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏ô‡∏¥‡πÄ‡∏¢‡πà #‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏™‡∏ß‡∏¢‡∏î‡∏µ üòÇüòÇ                                                                                                                                                   \n",
       "25525  ‡∏ñ‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á CR-V ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ú‡∏°‡∏ä‡∏≠‡∏ö‡πÇ‡∏â‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏Ñ‡∏°‡∏£‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡∏£‡∏ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏•‡πâ‡∏≤‡∏ô‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏ñ‡∏∂‡∏á‡∏•‡πâ‡∏≤‡∏ô‡∏õ‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏ó ‡∏ú‡∏°‡∏Å‡πá‡∏Ñ‡∏á‡πÄ‡∏•‡πà‡∏ô SUV ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞   \n",
       "9158   ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏≤‡∏≤ ^^                                                                                                                                                                      \n",
       "\n",
       "          label  \\\n",
       "7264   neutral    \n",
       "9199   neutral    \n",
       "3187   positive   \n",
       "25525  negative   \n",
       "9158   neutral    \n",
       "\n",
       "                                                                                                                                                                                  preprocessed  \\\n",
       "7264   ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏î‡∏µ‡∏Å‡πà‡∏≤‡∏™‡∏≤                                                                                                                                                                             \n",
       "9199   ‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏°‡∏©‡∏≤‡πÑ‡∏õ‡∏Å‡∏±‡∏ô                                                                                                                                                                      \n",
       "3187   ‡πÄ‡∏à‡πâ‡πÜ ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏ô‡∏¥‡πÄ‡∏¢‡πà  üòÇ  üòÇ                                                                                                                                                              \n",
       "25525  ‡∏ñ‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏π‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á cr-v ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ú‡∏°‡∏ä‡∏≠‡∏ö‡πÇ‡∏â‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏Ñ‡∏°‡∏£‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡∏£‡∏ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏•‡πâ‡∏≤‡∏ô‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏ñ‡∏∂‡∏á‡∏•‡πâ‡∏≤‡∏ô‡∏õ‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏ó ‡∏ú‡∏°‡∏Å‡πá‡∏Ñ‡∏á‡πÄ‡∏•‡πà‡∏ô suv ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞   \n",
       "9158   ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏≤‡∏≤ ^^                                                                                                                                                                      \n",
       "\n",
       "              hashtags  \\\n",
       "7264   []                \n",
       "9199   []                \n",
       "3187   [#‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏™‡∏ß‡∏¢‡∏î‡∏µ]   \n",
       "25525  []                \n",
       "9158   []                \n",
       "\n",
       "                                                                                                                                                                                                                                                              tokens  \n",
       "7264   [‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ, ‡∏î‡∏µ‡∏Å‡πà‡∏≤, ‡∏™‡∏≤]                                                                                                                                                                                                                                            \n",
       "9199   [‡∏™‡∏ô‡πÉ‡∏à, ‡πÑ‡∏´‡∏°, ‡∏ä‡πà‡∏ß‡∏á, ‡πÄ‡∏°‡∏©‡∏≤, ‡πÑ‡∏õ, ‡∏Å‡∏±‡∏ô]                                                                                                                                                                                                                               \n",
       "3187   [‡πÄ‡∏à‡πâ, ‡πÜ, ‡πÄ‡∏´‡πá‡∏ô, ‡∏ß‡πà‡∏≤, ‡πÉ‡∏ä‡πâ, ‡∏Å‡∏≤, ‡∏ô‡∏¥, ‡πÄ‡∏¢‡πà, üòÇ, üòÇ]                                                                                                                                                                                                                    \n",
       "25525  [‡∏ñ‡πâ‡∏≤, ‡πÅ‡∏ö‡∏ö, ‡∏ô‡∏±‡πâ‡∏ô, ‡∏Ñ‡∏á, ‡∏ï‡πâ‡∏≠‡∏á, ‡∏î‡∏π, ‡∏¢‡∏≠‡∏î, ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á, ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á, ‡∏ß‡πà‡∏≤, ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤, ‡∏°‡∏±‡πâ‡∏¢, ‡πÅ‡∏ï‡πà, ‡∏ú‡∏°, ‡∏ä‡∏≠‡∏ö, ‡πÇ‡∏â‡∏°, ‡∏ô‡∏µ‡πâ, ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤, ‡πÅ‡∏Ñ‡∏°, ‡∏£‡∏µ‡πà, ‡πÉ‡∏´‡∏°‡πà, ‡∏ô‡∏∞, ‡πÅ‡∏ï‡πà, ‡∏ñ‡πâ‡∏≤, ‡πÄ‡∏õ‡πá‡∏ô, ‡πÉ‡∏ô, ‡πÄ‡∏°‡∏∑‡∏≠‡∏á, ‡πÑ‡∏ó‡∏¢, ‡∏£‡∏ñ, ‡∏£‡∏≤‡∏Ñ‡∏≤, ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì, ‡∏•‡πâ‡∏≤‡∏ô, ‡∏Ñ‡∏£‡∏∂‡πà‡∏á, ‡∏ñ‡∏∂‡∏á, ‡∏•‡πâ‡∏≤‡∏ô, ‡∏õ‡∏•‡∏≤‡∏¢, ‡πÅ‡∏ö‡∏ö, ‡πÅ‡∏≠‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå, ‡∏ó, ‡∏ú‡∏°, ‡∏Å‡πá, ‡∏Ñ‡∏á, ‡πÄ‡∏•‡πà‡∏ô, suv, ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞]  \n",
       "9158   [‡πÑ‡∏°‡πà‡∏°‡∏µ, ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢, ‡∏Ñ‡πà‡∏≤, ‡∏≤‡∏≤]                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training Sentiment Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from preprocess import _return_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "  ('vectorzier', TfidfVectorizer(preprocessor= _return_token, \n",
    "                                 tokenizer= _return_token, \n",
    "                                 min_df= 5, \n",
    "                                 max_df= 0.85,\n",
    "                                 ngram_range= (1,2)\n",
    "                                )),\n",
    "  ('model', LogisticRegression(random_state=0,\n",
    "                               solver='liblinear',\n",
    "                               multi_class='ovr',\n",
    "                               class_weight='balanced'\n",
    "                              ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorzier',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.85, max_features=None,\n",
       "                                 min_df=5, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=<function _return_token at 0x11b2a92f0>,\n",
       "                                 smooth_idf=True, stop_words=None,\n",
       "                                 strip_accents=N...\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function _return_token at 0x11b2a92f0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='ovr', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(sentiment_df['tokens'], sentiment_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Evaluating Sentiment Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validate_prf1(splits, X, y, pipeline, average_method):\n",
    "    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    for train, test in kfold.split(X, y):\n",
    "        lr_fit = pipeline.fit(X[train], y[train])\n",
    "        prediction = lr_fit.predict(X[test])\n",
    "        scores = lr_fit.score(X[test],y[test])\n",
    "        \n",
    "        accuracy.append(scores * 100)\n",
    "        precision.append(precision_score(y[test], prediction, average=average_method)*100)\n",
    "        recall.append(recall_score(y[test], prediction, average=average_method)*100)\n",
    "        f1.append(f1_score(y[test], prediction, average=average_method)*100)\n",
    "\n",
    "        print(classification_report(y[test], prediction, digits=4))\n",
    "\n",
    "    print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "    print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "    print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6875    0.7258    0.7061       682\n",
      "     neutral     0.7681    0.7791    0.7736      1458\n",
      "    positive     0.5847    0.5126    0.5463       478\n",
      "\n",
      "    accuracy                         0.7166      2618\n",
      "   macro avg     0.6801    0.6725    0.6753      2618\n",
      "weighted avg     0.7136    0.7166    0.7145      2618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7117    0.7408    0.7260       683\n",
      "     neutral     0.7602    0.7831    0.7715      1457\n",
      "    positive     0.5517    0.4686    0.5068       478\n",
      "\n",
      "    accuracy                         0.7147      2618\n",
      "   macro avg     0.6745    0.6642    0.6681      2618\n",
      "weighted avg     0.7095    0.7147    0.7113      2618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7191    0.7423    0.7305       683\n",
      "     neutral     0.7707    0.8051    0.7875      1457\n",
      "    positive     0.5959    0.4874    0.5362       478\n",
      "\n",
      "    accuracy                         0.7307      2618\n",
      "   macro avg     0.6953    0.6783    0.6848      2618\n",
      "weighted avg     0.7253    0.7307    0.7268      2618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7424    0.7555    0.7489       683\n",
      "     neutral     0.7800    0.8078    0.7937      1457\n",
      "    positive     0.5845    0.5063    0.5426       478\n",
      "\n",
      "    accuracy                         0.7391      2618\n",
      "   macro avg     0.7023    0.6899    0.6951      2618\n",
      "weighted avg     0.7345    0.7391    0.7361      2618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7042    0.7599    0.7310       683\n",
      "     neutral     0.7647    0.7783    0.7714      1457\n",
      "    positive     0.5804    0.4833    0.5274       478\n",
      "\n",
      "    accuracy                         0.7196      2618\n",
      "   macro avg     0.6831    0.6738    0.6766      2618\n",
      "weighted avg     0.7152    0.7196    0.7163      2618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6880    0.7082    0.6980       682\n",
      "     neutral     0.7583    0.8030    0.7800      1457\n",
      "    positive     0.6129    0.4770    0.5365       478\n",
      "\n",
      "    accuracy                         0.7188      2617\n",
      "   macro avg     0.6864    0.6627    0.6715      2617\n",
      "weighted avg     0.7134    0.7188    0.7141      2617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7293    0.7507    0.7399       682\n",
      "     neutral     0.7719    0.7989    0.7852      1457\n",
      "    positive     0.5774    0.4916    0.5311       478\n",
      "\n",
      "    accuracy                         0.7302      2617\n",
      "   macro avg     0.6929    0.6804    0.6854      2617\n",
      "weighted avg     0.7253    0.7302    0.7270      2617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7090    0.7287    0.7187       682\n",
      "     neutral     0.7525    0.7783    0.7652      1457\n",
      "    positive     0.5697    0.4874    0.5254       478\n",
      "\n",
      "    accuracy                         0.7123      2617\n",
      "   macro avg     0.6771    0.6648    0.6698      2617\n",
      "weighted avg     0.7078    0.7123    0.7093      2617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7059    0.7390    0.7221       682\n",
      "     neutral     0.7740    0.7867    0.7803      1458\n",
      "    positive     0.5629    0.4969    0.5278       477\n",
      "\n",
      "    accuracy                         0.7214      2617\n",
      "   macro avg     0.6809    0.6742    0.6767      2617\n",
      "weighted avg     0.7178    0.7214    0.7191      2617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7072    0.7082    0.7077       682\n",
      "     neutral     0.7629    0.8121    0.7867      1458\n",
      "    positive     0.6021    0.4822    0.5355       477\n",
      "\n",
      "    accuracy                         0.7249      2617\n",
      "   macro avg     0.6907    0.6675    0.6766      2617\n",
      "weighted avg     0.7191    0.7249    0.7203      2617\n",
      "\n",
      "accuracy: 72.28% (+/- 0.80%)\n",
      "precision: 71.81% (+/- 0.78%)\n",
      "recall: 72.28% (+/- 0.80%)\n",
      "f1 score: 71.95% (+/- 0.79%)\n"
     ]
    }
   ],
   "source": [
    "kfold_cross_validate_prf1(10, sentiment_df['tokens'], sentiment_df['label'], pipeline, 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Predicting Text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12151496, 0.1676746 , 0.71081044]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '‡∏Å‡∏£‡∏∞‡πÄ‡∏û‡∏£‡∏≤‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å'\n",
    "tokens = tokenize(text)\n",
    "pipeline.predict_proba([tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Save Trained Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/tfidf_lr.pkl'\n",
    "\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
